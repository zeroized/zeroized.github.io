# 卷首语
2020/06/11

于研究生毕业答辩前2日

### 动机和初心

其实这应该是一个比较紧张的时间节点，现在应该是准备答辩的时间，然后紧接着就是准备学位申请材料，准备入职，正式入职。

但笔者认为这是人生前半段中最后的清闲时刻了，因此选择在这个时间点做一些开源和分享的工作，
既是对过去18年学习生涯的一个总结回顾，也是对后续几十年工作生涯的一个新的开篇。

笔者做分享已经很多年了。自2015年进入项目团队起，就一直作为团队的先行者探索新技术新方法的可能性，
几乎每一周都在团队例会上分享大大小小的各种技术、框架和算法。

从在白板上演算、绘图的口头分享，转变成逻辑严谨的论文解析，对笔者而言还稍有些不适应，
因此在算法的各个详解篇中可能会夹杂一些“俗”的表述方式，各位看官还请多多谅解。

对于笔者而言，分享，尤其是知识的分享是生活中的一个重要部分，往往在分享的过程中就能产生新的理解、得到新的收获。
希望能够通过这个博客将这种分享的习惯一直延续下去吧。

希望各位读者也能够在笔者的技术分享中获得启发，在推荐领域的研究中更进一步。

### 关于推荐系统领域

在机器学习和深度学习领域，比推荐方向热门的多的是，无论是CV、NLP等具体的方向，还是RL、知识图谱这些基础性的方向。

推荐系统进入工业界比上述所有的算法都要早不少，因此推荐系统领域也因此获得了两个独有的特点：极其贴近数据、发展缓慢。

下面笔者来简单谈谈这两个特点的成因。

从算法和模型所使用的数据角度来看，CV和NLP领域在各个子任务上大多有着类似“业界标准”的数据集，
像ImageNet、CIFAR等等，所有的研究人员都在这些“标准”数据集上同台竞争。
另一方面，在样本的质量上，CV和NLP的数据，
只有“好的样本”和“坏的样本”，并不存在“不对的样本”。

如果稍微研究一下推荐系统的相关顶会论文，顶会中推荐系统相关的文章大多被大型商业公司包揽，
而各个公司的方法在模型完全不相同的情况下达到的AUC却也差不太多。
因为每家公司面对的真实数据分布完全不同，一个模型放到新的数据里就不work了是十分正常的事情。
对照上面所说的样本问题来说，拿同为电商平台的阿里数据和亚马逊数据来举例子，
“中国样本”放到美亚去做预测，就是“不对的样本”，把美亚的“美国样本”放到阿里来也是同样的。

从数据角度出发就很容易推导出发展缓慢的问题。
因为大家都拿着标准数据在跑，所以在CV和NLP领域发展出了一种“方法>数据”的形态，
大牛们忙着开发新的模型结构，小牛们微调结构来刷SOTA榜，整个研究方向欣欣向荣。
而在推荐系统领域，各种大学实验室难以接触到真实的业界数据，只能拿老的公开数据集做实验，
而数据分布的时效性也在这方面发挥的巨大的负面作用，实验室产品放到工业界大部分都是不能work的。
因此研究人员的主力军队，大学实验室中的研究生，难堪推动推荐系统领域发展的大任。

当然，还有一个角度就是产品的质量角度。CV和NLP对产品的质量要求是很高的，
图像分类对就是对、错就是错，文本翻译的结果稍微有一点语言知识就能看出好与坏。
但推荐的结果本身就是很难量化的，很难说推荐得好不好——
因为一个推荐结果列表中，往往用户只会点选其中的1、2个，那其他的结果就不好了吗？
大多数这个时候只能说用户建模没有做好，而这和推荐算法的模型本身没有太大的关系。

总结一下，推荐系统是一门极其依赖、贴近数据的领域，
不仅表现在数据的分布会极大地导致模型异构，更是需要数据能够包含尽可能多的信息。
只有userid、movieid和timestamp3个字段的简版movielens数据，即使拿着像GPT-3般复杂的模型，又怎么能施展屠龙之技呢？


### 更新计划

在卷首语的最后，笔者罗列一下下一阶段更新的算法：
- 特征交叉 计划于六月底前完成更新
    - 综述篇——从LR到FLEN的进化与演变
    - FNN
    - PNN
    - Wide and Deep
    - DeepFM
    - DCN
- 序列推荐 计划于七月完成更新
    - 综述篇——RNN带来的变革与挑战
    - DIN
    - DIEN
    - DISN
    - GRU4Rec
- 嵌入方法 计划于八月完成更新
    - 综述篇——为什么我们不讨论数据稀疏性了
    - Deepwalk & node2vec
    - item2vec in Microsoft
    - SGNS in Aribnb
    - EGES in Alibaba
    - GBDT in Facebook

